[
  {
    "objectID": "labs/assignment1.html",
    "href": "labs/assignment1.html",
    "title": "Assignment 1: Census Data Quality for Policy Decisions",
    "section": "",
    "text": "You are a data analyst for the [California] Department of Human Services. The department is considering implementing an algorithmic system to identify communities that should receive priority for social service funding and outreach programs. Your supervisor has asked you to evaluate the quality and reliability of available census data to inform this decision.\nDrawing on our Week 2 discussion of algorithmic bias, you need to assess not just what the data shows, but how reliable it is and what communities might be affected by data quality issues.\n\n\n\n\nApply dplyr functions to real census data for policy analysis\nEvaluate data quality using margins of error\nConnect technical analysis to algorithmic decision-making\nIdentify potential equity implications of data reliability issues\nCreate professional documentation for policy stakeholders\n\n\n\n\nSubmit by posting your updated portfolio link on Canvas. Your assignment should be accessible at your-portfolio-url/assignments/assignment_1/\nMake sure to update your _quarto.yml navigation to include this assignment under an “Assignments” menu."
  },
  {
    "objectID": "labs/assignment1.html#scenario",
    "href": "labs/assignment1.html#scenario",
    "title": "Assignment 1: Census Data Quality for Policy Decisions",
    "section": "",
    "text": "You are a data analyst for the [California] Department of Human Services. The department is considering implementing an algorithmic system to identify communities that should receive priority for social service funding and outreach programs. Your supervisor has asked you to evaluate the quality and reliability of available census data to inform this decision.\nDrawing on our Week 2 discussion of algorithmic bias, you need to assess not just what the data shows, but how reliable it is and what communities might be affected by data quality issues."
  },
  {
    "objectID": "labs/assignment1.html#learning-objectives",
    "href": "labs/assignment1.html#learning-objectives",
    "title": "Assignment 1: Census Data Quality for Policy Decisions",
    "section": "",
    "text": "Apply dplyr functions to real census data for policy analysis\nEvaluate data quality using margins of error\nConnect technical analysis to algorithmic decision-making\nIdentify potential equity implications of data reliability issues\nCreate professional documentation for policy stakeholders"
  },
  {
    "objectID": "labs/assignment1.html#submission-instructions",
    "href": "labs/assignment1.html#submission-instructions",
    "title": "Assignment 1: Census Data Quality for Policy Decisions",
    "section": "",
    "text": "Submit by posting your updated portfolio link on Canvas. Your assignment should be accessible at your-portfolio-url/assignments/assignment_1/\nMake sure to update your _quarto.yml navigation to include this assignment under an “Assignments” menu."
  },
  {
    "objectID": "labs/assignment1.html#data-retrieval",
    "href": "labs/assignment1.html#data-retrieval",
    "title": "Assignment 1: Census Data Quality for Policy Decisions",
    "section": "2.1 Data Retrieval",
    "text": "2.1 Data Retrieval\nYour Task: Use get_acs() to retrieve county-level data for your chosen state.\nRequirements: - Geography: county level - Variables: median household income (B19013_001) and total population (B01003_001)\n- Year: 2022 - Survey: acs5 - Output format: wide\nHint: Remember to give your variables descriptive names using the variables = c(name = \"code\") syntax.\n\n# Write your get_acs() code here\n\ncounty_data &lt;- get_acs(\n  geography = \"county\",\n  variables = c(\n    median_income = \"B19013_001\",  \n    total_pop = \"B01003_001\"    \n  ),\n  state = my_state,\n  year = 2022,\n  output = \"wide\"\n)\n\n# Clean the county names to remove state name and \"County\" \n# Hint: use mutate() with str_remove()\n\ncounty_data &lt;- county_data %&gt;%\n  mutate(NAME = str_remove(NAME, \" County, California\"))\n\n# Display the first few rows\nhead(county_data)\n\n# A tibble: 6 × 6\n  GEOID NAME      median_incomeE median_incomeM total_popE total_popM\n  &lt;chr&gt; &lt;chr&gt;              &lt;dbl&gt;          &lt;dbl&gt;      &lt;dbl&gt;      &lt;dbl&gt;\n1 06001 Alameda           122488           1231    1663823         NA\n2 06003 Alpine            101125          17442       1515        206\n3 06005 Amador             74853           6048      40577         NA\n4 06007 Butte              66085           2261     213605         NA\n5 06009 Calaveras          77526           3875      45674         NA\n6 06011 Colusa             69619           5745      21811         NA"
  },
  {
    "objectID": "labs/assignment1.html#data-quality-assessment",
    "href": "labs/assignment1.html#data-quality-assessment",
    "title": "Assignment 1: Census Data Quality for Policy Decisions",
    "section": "2.2 Data Quality Assessment",
    "text": "2.2 Data Quality Assessment\nYour Task: Calculate margin of error percentages and create reliability categories.\nRequirements: - Calculate MOE percentage: (margin of error / estimate) * 100 - Create reliability categories: - High Confidence: MOE &lt; 5% - Moderate Confidence: MOE 5-10%\n- Low Confidence: MOE &gt; 10% - Create a flag for unreliable estimates (MOE &gt; 10%)\nHint: Use mutate() with case_when() for the categories.\n\n# Calculate MOE percentage and reliability categories using mutate()\n\ncounty_data &lt;- county_data %&gt;%\n  mutate(\n    income_moe_pct = (median_incomeM / median_incomeE) * 100,\n     reliability_category = case_when(\n      income_moe_pct &lt; 5 ~ \"High Confidence\",\n      income_moe_pct &lt;= 10 ~ \"Moderate Confidence\",\n      TRUE ~ \"Low Confidence\"),\n        unreliable_flag = income_moe_pct &gt; 10)\n\n# Create a summary showing count of counties in each reliability category\n# Hint: use count() and mutate() to add percentages\n\nreliability_summary &lt;- county_data %&gt;%\n  count(reliability_category) %&gt;%\n  mutate(\n    percentage = round(n / sum(n) * 100, 1)\n  )"
  },
  {
    "objectID": "labs/assignment1.html#high-uncertainty-counties",
    "href": "labs/assignment1.html#high-uncertainty-counties",
    "title": "Assignment 1: Census Data Quality for Policy Decisions",
    "section": "2.3 High Uncertainty Counties",
    "text": "2.3 High Uncertainty Counties\nYour Task: Identify the 5 counties with the highest MOE percentages.\nRequirements: - Sort by MOE percentage (highest first) - Select the top 5 counties - Display: county name, median income, margin of error, MOE percentage, reliability category - Format as a professional table using kable()\nHint: Use arrange(), slice(), and select() functions.\n\n# Create table of top 5 counties by MOE percentage\n\nhigh_uncertainty_table &lt;- county_data %&gt;%\n  arrange(desc(income_moe_pct)) %&gt;%  \n  slice_head(n = 5) %&gt;% \n  select(NAME, median_incomeE, median_incomeM, income_moe_pct, reliability_category)\n\n# Format as table with kable() - include appropriate column names and caption\n\nlibrary(knitr)\nlibrary(kableExtra)\n\nhigh_uncertainty_table %&gt;%\n  kable(\n    col.names = c(\"County\", \"Median Income\", \"Margin of Error\", \"MOE (%)\", \"Reliability\"),\n    caption = \"Top 5 California Counties with Highest Income Uncertainty\",\n    format.args = list(big.mark = \",\"),\n    digits = c(0, 0, 0, 1, 0) \n  ) %&gt;%\n  kable_styling(bootstrap_options = c(\"striped\", \"hover\"))\n\n\nTop 5 California Counties with Highest Income Uncertainty\n\n\nCounty\nMedian Income\nMargin of Error\nMOE (%)\nReliability\n\n\n\n\nMono\n82,038\n15,388\n18.8\nLow Confidence\n\n\nAlpine\n101,125\n17,442\n17.2\nLow Confidence\n\n\nSierra\n61,108\n9,237\n15.1\nLow Confidence\n\n\nTrinity\n47,317\n5,890\n12.4\nLow Confidence\n\n\nPlumas\n67,885\n7,772\n11.4\nLow Confidence\n\n\n\n\n\nData Quality Commentary:\n[Counties that have higher margin of error will have unreliable income estimates and could lead to misleading policy plan and resource allocation. The high margin of error could because these are counties that have low population and the data could easily skewed.]"
  },
  {
    "objectID": "labs/assignment1.html#focus-area-selection",
    "href": "labs/assignment1.html#focus-area-selection",
    "title": "Assignment 1: Census Data Quality for Policy Decisions",
    "section": "3.1 Focus Area Selection",
    "text": "3.1 Focus Area Selection\nYour Task: Select 2-3 counties from your reliability analysis for detailed tract-level study.\nStrategy: Choose counties that represent different reliability levels (e.g., 1 high confidence, 1 moderate, 1 low confidence) to compare how data quality varies.\n\n# Use filter() to select 2-3 counties from your county_reliability data\n# Store the selected counties in a variable called selected_counties\n\nselected_counties &lt;- county_data %&gt;%\n  filter(NAME %in% c(\"Los Angeles\", \"Trinity\", \"Tehama\")) %&gt;%\n  select(NAME, median_incomeE, income_moe_pct, reliability_category)\n\n# Display the selected counties with their key characteristics\n# Show: county name, median income, MOE percentage, reliability category\n\nprint(selected_counties)\n\n# A tibble: 3 × 4\n  NAME        median_incomeE income_moe_pct reliability_category\n  &lt;chr&gt;                &lt;dbl&gt;          &lt;dbl&gt; &lt;chr&gt;               \n1 Los Angeles          83411          0.526 High Confidence     \n2 Tehama               59029          6.95  Moderate Confidence \n3 Trinity              47317         12.4   Low Confidence      \n\n\nComment on the output: [Los Angeles has a High Confidence category because of its extremely low income margin of error percent. This is because Los Angeles is one of the most populated county and that lead to low margin of error. On the another other hand, Tehama has a income margin of error percentage around 7 and Trinity is at 12. The data for Tehama and Trinity are less reliable compare to Los Angeles County.]"
  },
  {
    "objectID": "labs/assignment1.html#tract-level-demographics",
    "href": "labs/assignment1.html#tract-level-demographics",
    "title": "Assignment 1: Census Data Quality for Policy Decisions",
    "section": "3.2 Tract-Level Demographics",
    "text": "3.2 Tract-Level Demographics\nYour Task: Get demographic data for census tracts in your selected counties.\nRequirements: - Geography: tract level - Variables: white alone (B03002_003), Black/African American (B03002_004), Hispanic/Latino (B03002_012), total population (B03002_001) - Use the same state and year as before - Output format: wide - Challenge: You’ll need county codes, not names. Look at the GEOID patterns in your county data for hints.\n\n# Define your race/ethnicity variables with descriptive names\n\nrace_vars &lt;- c(\n  total_pop = \"B03002_001\",\n  white_alone = \"B03002_003\",\n  black_alone = \"B03002_004\",\n  hispanic = \"B03002_012\"\n)\n\n# Use get_acs() to retrieve tract-level data\n# Hint: You may need to specify county codes in the county parameter\n\ntract_demographics &lt;- get_acs(\n  geography = \"tract\",\n  variables = race_vars,\n  state = my_state,\n  county = c(\"037\", \"105\", \"103\"),\n  year = 2022,\n  output = \"wide\"\n)\n\n# Calculate percentage of each group using mutate()\n# Create percentages for white, Black, and Hispanic populations\n\ntract_demographics &lt;- tract_demographics %&gt;%\n  mutate(\n    white_pct = (white_aloneE / total_popE) * 100,\n    black_pct = (black_aloneE / total_popE) * 100,\n    hispanic_pct = (hispanicE / total_popE) * 100\n  )\n\n# Add readable tract and county name columns using str_extract() or similar\n\ntract_demographics &lt;- tract_demographics %&gt;%\n  mutate(\n    census_tract = str_remove(NAME, \";.*\"),\n    county = str_remove(NAME, \"Census Tract [0-9.]+; \") %&gt;%\n             str_remove(\"; California\") %&gt;%\n             str_remove(\" County\")\n  )"
  },
  {
    "objectID": "labs/assignment1.html#demographic-analysis",
    "href": "labs/assignment1.html#demographic-analysis",
    "title": "Assignment 1: Census Data Quality for Policy Decisions",
    "section": "3.3 Demographic Analysis",
    "text": "3.3 Demographic Analysis\nYour Task: Analyze the demographic patterns in your selected areas.\n\n# Find the tract with the highest percentage of Hispanic/Latino residents\n# Hint: use arrange() and slice() to get the top tract\n\nhighest_hispanic &lt;- tract_demographics %&gt;%\n  arrange(desc(hispanic_pct)) %&gt;%\n  slice_head(n = 1) %&gt;%\n  select(census_tract, county, hispanic_pct)\n\n# Calculate average demographics by county using group_by() and summarize()\n# Show: number of tracts, average percentage for each racial/ethnic group\n\ncounty_demographics &lt;- tract_demographics %&gt;%\n  group_by(county) %&gt;%\n  summarize(\n    num_tracts = n(),\n    avg_white_pct = mean(white_pct, na.rm = TRUE),\n    avg_black_pct = mean(black_pct, na.rm = TRUE),\n    avg_hispanic_pct = mean(hispanic_pct, na.rm = TRUE)\n  )\n\n# Create a nicely formatted table of your results using kable()\n\nlibrary(knitr)          \ncounty_demographics %&gt;%\n  kable(\n    col.names = c(\"County\", \"Number of Tracts\", \"Avg White %\", \"Avg Black %\", \"Avg Hispanic %\"), \n    caption = \"Average Demographics by County\",  \n    digits = 1           \n  )\n\n\nAverage Demographics by County\n\n\n\n\n\n\n\n\n\nCounty\nNumber of Tracts\nAvg White %\nAvg Black %\nAvg Hispanic %\n\n\n\n\nLos Angeles\n2498\n26.3\n7.6\n47.6\n\n\nTehama\n14\n65.9\n0.9\n26.0\n\n\nTrinity\n4\n79.2\n1.7\n7.0"
  },
  {
    "objectID": "labs/assignment1.html#moe-analysis-for-demographic-variables",
    "href": "labs/assignment1.html#moe-analysis-for-demographic-variables",
    "title": "Assignment 1: Census Data Quality for Policy Decisions",
    "section": "4.1 MOE Analysis for Demographic Variables",
    "text": "4.1 MOE Analysis for Demographic Variables\nYour Task: Examine margins of error for demographic variables to see if some communities have less reliable data.\nRequirements: - Calculate MOE percentages for each demographic variable - Flag tracts where any demographic variable has MOE &gt; 15% - Create summary statistics\n\n# Calculate MOE percentages for white, Black, and Hispanic variables\n# Hint: use the same formula as before (margin/estimate * 100)\n\ntract_demographics &lt;- tract_demographics %&gt;%\n  mutate(\n    white_moe_pct = (white_aloneM / white_aloneE) * 100,\n    black_moe_pct = (black_aloneM / black_aloneE) * 100,\n    hispanic_moe_pct = (hispanicM / hispanicE) * 100,\n    high_moe_flag = ifelse(white_moe_pct &gt; 15 | black_moe_pct &gt; 15 | hispanic_moe_pct &gt; 15, TRUE, FALSE)\n  )\n\n# Create a flag for tracts with high MOE on any demographic variable\n# Use logical operators (| for OR) in an ifelse() statement\n\n# Create summary statistics showing how many tracts have data quality issues\n\nmoe_summary &lt;- tract_demographics %&gt;%\n  summarize(\n    total_tracts = n(),\n    tracts_with_issues = sum(high_moe_flag, na.rm = TRUE),\n    pct_with_issues = round(sum(high_moe_flag, na.rm = TRUE) / n() * 100, 1)\n  )\n\nmoe_summary\n\n# A tibble: 1 × 3\n  total_tracts tracts_with_issues pct_with_issues\n         &lt;int&gt;              &lt;int&gt;           &lt;dbl&gt;\n1         2516               2515             100"
  },
  {
    "objectID": "labs/assignment1.html#pattern-analysis",
    "href": "labs/assignment1.html#pattern-analysis",
    "title": "Assignment 1: Census Data Quality for Policy Decisions",
    "section": "4.2 Pattern Analysis",
    "text": "4.2 Pattern Analysis\nYour Task: Investigate whether data quality problems are randomly distributed or concentrated in certain types of communities.\n\n# Group tracts by whether they have high MOE issues\n# Calculate average characteristics for each group:\n# - population size, demographic percentages\n\npattern_comparison &lt;- tract_demographics %&gt;%\n  group_by(high_moe_flag) %&gt;%\n  summarize(\n    num_tracts = n(),\n    avg_population = mean(total_popE, na.rm = TRUE),\n    avg_pct_white = mean(white_pct, na.rm = TRUE),\n    avg_pct_black = mean(black_pct, na.rm = TRUE),\n    avg_pct_hispanic = mean(hispanic_pct, na.rm = TRUE)\n  )\n\n# Use group_by() and summarize() to create this comparison\n# Create a professional table showing the patterns\n\nlibrary(knitr)\npattern_comparison %&gt;%\n  kable(\n    col.names = c(\"High MOE Issues\", \"Number of Tracts\", \"Avg Population\", \n                  \"Avg White% \", \"Avg Black %\", \"Avg Hispanic %\"),\n    caption = \"Comparison of Tract Characteristics by Data Quality\",\n    digits = c(0, 0, 0, 1, 1, 1)\n  )\n\n\nComparison of Tract Characteristics by Data Quality\n\n\n\n\n\n\n\n\n\n\nHigh MOE Issues\nNumber of Tracts\nAvg Population\nAvg White%\nAvg Black %\nAvg Hispanic %\n\n\n\n\nFALSE\n1\n8994\n16.8\n33.6\n41.4\n\n\nTRUE\n2515\n3980\n26.6\n7.5\n47.4\n\n\n\n\n\nPattern Analysis: [It is crazy that almost all of the data are not reliable. The estimate for racial group is not reliable on the census tract level through their high margin of error. I think this might further stress the point of how sampling population is critical in doing analysis. The average population for all the HIGH MOE Issues tracts is at 3980. The only one tract without HIGH MOE Issue has a population 0f 8994.]"
  },
  {
    "objectID": "labs/assignment1.html#analysis-integration-and-professional-summary",
    "href": "labs/assignment1.html#analysis-integration-and-professional-summary",
    "title": "Assignment 1: Census Data Quality for Policy Decisions",
    "section": "5.1 Analysis Integration and Professional Summary",
    "text": "5.1 Analysis Integration and Professional Summary\nYour Task: Write an executive summary that integrates findings from all four analyses.\nExecutive Summary Requirements: 1. Overall Pattern Identification: What are the systematic patterns across all your analyses? 2. Equity Assessment: Which communities face the greatest risk of algorithmic bias based on your findings? 3. Root Cause Analysis: What underlying factors drive both data quality issues and bias risk? 4. Strategic Recommendations: What should the Department implement to address these systematic issues?\nExecutive Summary:\n[I think the most important takeaway from this assignment is the important of sampling size. This situation has appear in multiple analysis and multple times. If a data has some reliability issue, one of the characteristic of that data is the small sampling size.\nThe community that faced the greatest risk of algorithmic bias is Trinity. Trinity only has 4 census tract and it such a small county that the data could highly likely to be skewed because of sampling error. It is also show as a “Low Confidence” in county level income data. The interpretation and result could be really not reliable due to data quality issue.\nThe root cause may be the survey design and also just how insufficient for the data to be reliable if we want to look at small geographic areas like census tracts. Rural places like Trinity and Tehama make reliable sampling really challenging.\nI think one of the most important is to apply strict MOE thresholds. Data that are not reliable especially on small sample and big geographic area it is really important to examine the data closely. Aggregate the data and looking at large scale is necessary if the public organization want to implement any policies. Careful decision making process is necessary and key for community success. ]"
  },
  {
    "objectID": "labs/assignment1.html#specific-recommendations",
    "href": "labs/assignment1.html#specific-recommendations",
    "title": "Assignment 1: Census Data Quality for Policy Decisions",
    "section": "6.3 Specific Recommendations",
    "text": "6.3 Specific Recommendations\nYour Task: Create a decision framework for algorithm implementation.\n\n# Create a summary table using your county reliability data\n# Include: county name, median income, MOE percentage, reliability category\n\ndecision_framework &lt;- county_data %&gt;%\n  select(NAME, median_incomeE, income_moe_pct, reliability_category) %&gt;%\n  mutate(\n    algorithm_recommendation = case_when(\n      reliability_category == \"High Confidence\" ~ \"Safe for algorithmic decisions\",\n      reliability_category == \"Moderate Confidence\" ~ \"Use with caution - monitor outcomes\",\n      reliability_category == \"Low Confidence\" ~ \"Requires manual review or additional data\"\n    )\n  )\n\n# Add a new column with algorithm recommendations using case_when():\n# - High Confidence: \"Safe for algorithmic decisions\"\n# - Moderate Confidence: \"Use with caution - monitor outcomes\"  \n# - Low Confidence: \"Requires manual review or additional data\"\n\n# Format as a professional table with kable()\n\nlibrary(knitr)\nlibrary(kableExtra)\n\ndecision_framework %&gt;%\n  kable(\n    col.names = c(\"County\", \"Median Income\", \"MOE %\", \"Reliability\", \"Algorithm Recommendation\"),\n    caption = \"Decision Framework for Algorithm Implementation by County\",\n    format.args = list(big.mark = \",\"),\n    digits = c(0, 0, 1, 0, 0)\n  ) %&gt;%\n  kable_styling(bootstrap_options = c(\"striped\", \"hover\"))\n\n\nDecision Framework for Algorithm Implementation by County\n\n\nCounty\nMedian Income\nMOE %\nReliability\nAlgorithm Recommendation\n\n\n\n\nAlameda\n122,488\n1.0\nHigh Confidence\nSafe for algorithmic decisions\n\n\nAlpine\n101,125\n17.2\nLow Confidence\nRequires manual review or additional data\n\n\nAmador\n74,853\n8.1\nModerate Confidence\nUse with caution - monitor outcomes\n\n\nButte\n66,085\n3.4\nHigh Confidence\nSafe for algorithmic decisions\n\n\nCalaveras\n77,526\n5.0\nHigh Confidence\nSafe for algorithmic decisions\n\n\nColusa\n69,619\n8.3\nModerate Confidence\nUse with caution - monitor outcomes\n\n\nContra Costa\n120,020\n1.2\nHigh Confidence\nSafe for algorithmic decisions\n\n\nDel Norte\n61,149\n7.2\nModerate Confidence\nUse with caution - monitor outcomes\n\n\nEl Dorado\n99,246\n3.4\nHigh Confidence\nSafe for algorithmic decisions\n\n\nFresno\n67,756\n1.4\nHigh Confidence\nSafe for algorithmic decisions\n\n\nGlenn\n64,033\n6.2\nModerate Confidence\nUse with caution - monitor outcomes\n\n\nHumboldt\n57,881\n3.7\nHigh Confidence\nSafe for algorithmic decisions\n\n\nImperial\n53,847\n4.1\nHigh Confidence\nSafe for algorithmic decisions\n\n\nInyo\n63,417\n8.6\nModerate Confidence\nUse with caution - monitor outcomes\n\n\nKern\n63,883\n2.1\nHigh Confidence\nSafe for algorithmic decisions\n\n\nKings\n68,540\n3.3\nHigh Confidence\nSafe for algorithmic decisions\n\n\nLake\n56,259\n4.3\nHigh Confidence\nSafe for algorithmic decisions\n\n\nLassen\n59,515\n6.0\nModerate Confidence\nUse with caution - monitor outcomes\n\n\nLos Angeles\n83,411\n0.5\nHigh Confidence\nSafe for algorithmic decisions\n\n\nMadera\n73,543\n3.9\nHigh Confidence\nSafe for algorithmic decisions\n\n\nMarin\n142,019\n2.9\nHigh Confidence\nSafe for algorithmic decisions\n\n\nMariposa\n60,021\n8.8\nModerate Confidence\nUse with caution - monitor outcomes\n\n\nMendocino\n61,335\n3.6\nHigh Confidence\nSafe for algorithmic decisions\n\n\nMerced\n64,772\n3.3\nHigh Confidence\nSafe for algorithmic decisions\n\n\nModoc\n54,962\n9.8\nModerate Confidence\nUse with caution - monitor outcomes\n\n\nMono\n82,038\n18.8\nLow Confidence\nRequires manual review or additional data\n\n\nMonterey\n91,043\n2.1\nHigh Confidence\nSafe for algorithmic decisions\n\n\nNapa\n105,809\n2.8\nHigh Confidence\nSafe for algorithmic decisions\n\n\nNevada\n79,395\n4.8\nHigh Confidence\nSafe for algorithmic decisions\n\n\nOrange\n109,361\n0.8\nHigh Confidence\nSafe for algorithmic decisions\n\n\nPlacer\n109,375\n1.7\nHigh Confidence\nSafe for algorithmic decisions\n\n\nPlumas\n67,885\n11.4\nLow Confidence\nRequires manual review or additional data\n\n\nRiverside\n84,505\n1.3\nHigh Confidence\nSafe for algorithmic decisions\n\n\nSacramento\n84,010\n1.0\nHigh Confidence\nSafe for algorithmic decisions\n\n\nSan Benito\n104,451\n5.2\nModerate Confidence\nUse with caution - monitor outcomes\n\n\nSan Bernardino\n77,423\n1.0\nHigh Confidence\nSafe for algorithmic decisions\n\n\nSan Diego\n96,974\n1.0\nHigh Confidence\nSafe for algorithmic decisions\n\n\nSan Francisco\n136,689\n1.4\nHigh Confidence\nSafe for algorithmic decisions\n\n\nSan Joaquin\n82,837\n1.7\nHigh Confidence\nSafe for algorithmic decisions\n\n\nSan Luis Obispo\n90,158\n2.6\nHigh Confidence\nSafe for algorithmic decisions\n\n\nSan Mateo\n149,907\n1.7\nHigh Confidence\nSafe for algorithmic decisions\n\n\nSanta Barbara\n92,332\n2.0\nHigh Confidence\nSafe for algorithmic decisions\n\n\nSanta Clara\n153,792\n1.0\nHigh Confidence\nSafe for algorithmic decisions\n\n\nSanta Cruz\n104,409\n3.0\nHigh Confidence\nSafe for algorithmic decisions\n\n\nShasta\n68,347\n3.6\nHigh Confidence\nSafe for algorithmic decisions\n\n\nSierra\n61,108\n15.1\nLow Confidence\nRequires manual review or additional data\n\n\nSiskiyou\n53,898\n4.9\nHigh Confidence\nSafe for algorithmic decisions\n\n\nSolano\n97,037\n1.8\nHigh Confidence\nSafe for algorithmic decisions\n\n\nSonoma\n99,266\n2.0\nHigh Confidence\nSafe for algorithmic decisions\n\n\nStanislaus\n74,872\n1.8\nHigh Confidence\nSafe for algorithmic decisions\n\n\nSutter\n72,654\n4.7\nHigh Confidence\nSafe for algorithmic decisions\n\n\nTehama\n59,029\n7.0\nModerate Confidence\nUse with caution - monitor outcomes\n\n\nTrinity\n47,317\n12.4\nLow Confidence\nRequires manual review or additional data\n\n\nTulare\n64,474\n2.3\nHigh Confidence\nSafe for algorithmic decisions\n\n\nTuolumne\n70,432\n6.7\nModerate Confidence\nUse with caution - monitor outcomes\n\n\nVentura\n102,141\n1.5\nHigh Confidence\nSafe for algorithmic decisions\n\n\nYolo\n85,097\n2.7\nHigh Confidence\nSafe for algorithmic decisions\n\n\nYuba\n66,693\n4.2\nHigh Confidence\nSafe for algorithmic decisions\n\n\n\n\n\nKey Recommendations:\nYour Task: Use your analysis results to provide specific guidance to the department.\n\nhigh_confidence &lt;- decision_framework %&gt;%\n  filter(reliability_category == \"High Confidence\") %&gt;%\n  select(NAME)\n\nmoderate_confidence &lt;- decision_framework %&gt;%\n  filter(reliability_category == \"Moderate Confidence\") %&gt;%\n  select(NAME)\n\nlow_confidence &lt;- decision_framework %&gt;%\n  filter(reliability_category == \"Low Confidence\") %&gt;%\n  select(NAME)\n\nprint(\"High Confidence Counties:\")\n\n[1] \"High Confidence Counties:\"\n\nprint(high_confidence)\n\n# A tibble: 42 × 1\n   NAME        \n   &lt;chr&gt;       \n 1 Alameda     \n 2 Butte       \n 3 Calaveras   \n 4 Contra Costa\n 5 El Dorado   \n 6 Fresno      \n 7 Humboldt    \n 8 Imperial    \n 9 Kern        \n10 Kings       \n# ℹ 32 more rows\n\nprint(\"Moderate Confidence Counties:\")\n\n[1] \"Moderate Confidence Counties:\"\n\nprint(moderate_confidence)\n\n# A tibble: 11 × 1\n   NAME      \n   &lt;chr&gt;     \n 1 Amador    \n 2 Colusa    \n 3 Del Norte \n 4 Glenn     \n 5 Inyo      \n 6 Lassen    \n 7 Mariposa  \n 8 Modoc     \n 9 San Benito\n10 Tehama    \n11 Tuolumne  \n\nprint(\"Low Confidence Counties:\")\n\n[1] \"Low Confidence Counties:\"\n\nprint(low_confidence)\n\n# A tibble: 5 × 1\n  NAME   \n  &lt;chr&gt;  \n1 Alpine \n2 Mono   \n3 Plumas \n4 Sierra \n5 Trinity\n\n\n\nCounties suitable for immediate algorithmic implementation: [The counties that are suitabale for immediate algorithmic implementation are Alameda, Butte, Calaveras, Contra Costa, El Dorado, Fresno, Humboldt, Imperial, Kern, Kings, Lake, Los Angeles, Madera, Marin, Mendocino, Merced, Monterey, Napa, Nevada, Orange, Placer, Riverside, Sacramento, San Bernardino, San Diego, San Francisco, San Joaquin, San Luis Obispo, San Mateo, Santa Barbara, Santa Clara, Santa Cruz, Shasta, Siskiyou, Solano, Sonoma, Stanislaus, Sutter, Tulare, Ventura, Yolo, Yuba. These county are in the high confidence category for the new decision making framework.]\nCounties requiring additional oversight: [Counties need additional oversight are Amador, Colusa, Del Norte, Glenn, Inyo, Lassen, Mariposa, Modoc, San Benito, Tehama, Tuolumne. These county are in the moderate confidence category for the new decision making framework.]\nCounties needing alternative approaches: [Counties that need alternative approaches are Alpine, Mono, Plumas, Sierra, Trinity because they are in the low confidence category for the new decision making framework.]"
  },
  {
    "objectID": "labs/assignment1.html#questions-for-further-investigation",
    "href": "labs/assignment1.html#questions-for-further-investigation",
    "title": "Assignment 1: Census Data Quality for Policy Decisions",
    "section": "Questions for Further Investigation",
    "text": "Questions for Further Investigation\n[- How has the reliability of ACS estimates changed over time for small counties like Trinity? - Do neighboring census tracts with high MOEs cluster together spatially?]"
  },
  {
    "objectID": "labs/assignment1.html#submission-checklist",
    "href": "labs/assignment1.html#submission-checklist",
    "title": "Assignment 1: Census Data Quality for Policy Decisions",
    "section": "Submission Checklist",
    "text": "Submission Checklist\nBefore submitting your portfolio link on Canvas:\n\nAll code chunks run without errors\nAll “[Fill this in]” prompts have been completed\nTables are properly formatted and readable\nExecutive summary addresses all four required components\nPortfolio navigation includes this assignment\nCensus API key is properly set\nDocument renders correctly to HTML\n\nRemember: Submit your portfolio URL on Canvas, not the file itself. Your assignment should be accessible at your-portfolio-url/assignments/assignment_1/your_file_name.html"
  },
  {
    "objectID": "weekly-notes/week-03-notes.html",
    "href": "weekly-notes/week-03-notes.html",
    "title": "Week 3 Notes",
    "section": "",
    "text": "We learn some ways to do visualizations and the asethetic mapping. What is a ggplot. We also learned how to join data."
  },
  {
    "objectID": "weekly-notes/week-03-notes.html#key-concepts-learned",
    "href": "weekly-notes/week-03-notes.html#key-concepts-learned",
    "title": "Week 3 Notes",
    "section": "",
    "text": "We learn some ways to do visualizations and the asethetic mapping. What is a ggplot. We also learned how to join data."
  },
  {
    "objectID": "weekly-notes/week-03-notes.html#coding-techniques",
    "href": "weekly-notes/week-03-notes.html#coding-techniques",
    "title": "Week 3 Notes",
    "section": "Coding Techniques",
    "text": "Coding Techniques\n\nIn class, we learned the basics of ggplot2 and joins in dplyr. In ggplot2, aesthetic mappings like x, y, color, fill, size, shape, and alpha control visual elements such as position, color, and transparency. A typical plot follows the structure ggplot(data) + aes(x, y) + geom_something() + additional_layers(), and layers are added with +. We also covered data joins in dplyr: left_join() keeps all rows from the left dataset, right_join() keeps all from the right, inner_join() keeps only matching rows, and full_join() keeps all rows from both, with left_join() being the most common for adding columns to a main dataset."
  },
  {
    "objectID": "weekly-notes/week-03-notes.html#questions-challenges",
    "href": "weekly-notes/week-03-notes.html#questions-challenges",
    "title": "Week 3 Notes",
    "section": "Questions & Challenges",
    "text": "Questions & Challenges\n\nI think it is very important to follow all the steps correct to make everything work."
  },
  {
    "objectID": "weekly-notes/week-03-notes.html#connections-to-policy",
    "href": "weekly-notes/week-03-notes.html#connections-to-policy",
    "title": "Week 3 Notes",
    "section": "Connections to Policy",
    "text": "Connections to Policy\n\nLearning ggplot2 and dplyr helps us turn data into clear visuals and summaries that make policy trends easier to understand. This makes it simpler to spot patterns and share insights that can guide better, data-informed decisions."
  },
  {
    "objectID": "weekly-notes/week-03-notes.html#reflection",
    "href": "weekly-notes/week-03-notes.html#reflection",
    "title": "Week 3 Notes",
    "section": "Reflection",
    "text": "Reflection\n\nTo become more proficient in this process, it requires a lot of time. Even following the class excercise could be challenging. More practice!"
  },
  {
    "objectID": "weekly-notes/week-01-notes.html",
    "href": "weekly-notes/week-01-notes.html",
    "title": "Week 1 Notes - Course Introduction",
    "section": "",
    "text": "What is Git, Github, Quarto, and full term for YAML (YAML Ain’t Markup Language).\nSome basic R coding language and went over an example on CAR data."
  },
  {
    "objectID": "weekly-notes/week-01-notes.html#key-concepts-learned",
    "href": "weekly-notes/week-01-notes.html#key-concepts-learned",
    "title": "Week 1 Notes - Course Introduction",
    "section": "",
    "text": "What is Git, Github, Quarto, and full term for YAML (YAML Ain’t Markup Language).\nSome basic R coding language and went over an example on CAR data."
  },
  {
    "objectID": "weekly-notes/week-01-notes.html#coding-techniques",
    "href": "weekly-notes/week-01-notes.html#coding-techniques",
    "title": "Week 1 Notes - Course Introduction",
    "section": "Coding Techniques",
    "text": "Coding Techniques\n\nBold text\nItalic text\nBold and italic\ncode text\nStrikethrough\nselect() - choose columns\nfilter() - choose rows\nmutate() - create new variables\nsummarize() - calculate statistics\ngroup_by() - operate on groups]\ntitle: “My Analysis” author: “Your Name” date: today format: html"
  },
  {
    "objectID": "weekly-notes/week-01-notes.html#questions-challenges",
    "href": "weekly-notes/week-01-notes.html#questions-challenges",
    "title": "Week 1 Notes - Course Introduction",
    "section": "Questions & Challenges",
    "text": "Questions & Challenges\n\nI think it is hard to understand all the R code and notations.\nThis is my first time interact with R and Github. So I need to try everything first and I will find more challenges."
  },
  {
    "objectID": "weekly-notes/week-01-notes.html#connections-to-policy",
    "href": "weekly-notes/week-01-notes.html#connections-to-policy",
    "title": "Week 1 Notes - Course Introduction",
    "section": "Connections to Policy",
    "text": "Connections to Policy\n\nBoth the analysis and the data itself can be biased. The reason is that data were collected by someone who might be biased."
  },
  {
    "objectID": "weekly-notes/week-01-notes.html#reflection",
    "href": "weekly-notes/week-01-notes.html#reflection",
    "title": "Week 1 Notes - Course Introduction",
    "section": "Reflection",
    "text": "Reflection\n\nQuarto is really interesting. Looking forward to see more what Quarto can do.\nThrough our assignment. I think it will be a great practice for me."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "MUSA 5080 Portfolio",
    "section": "",
    "text": "This portfolio documents my learning journey in Public Policy Analytics (MUSA 5080).\n\n\nAdvanced spatial analysis and data science for urban planning and public policy.\n\n\n\n\nWeekly Notes: My learning reflections and key concepts\nAssignment: Completed assignments and analyses\nFinal Project: Capstone modeling challenge\n\n\n\n\n\nMy name is Ye and I did my Bachelor in Urban Planning at USC ✌️✌️.\nMy email is yezhang1@upenn.edu\nMy Github user name is yezhanggg\nI think it is a requirement. Also I don’t have any prior experience with R and I think it is powerful tool that would be really helpful for me to know. It has so many potential and implications that I could use in multiple areas and projects.\n\n\n\n\n\nEmail: [yezhang1@design.upenn.edu]\nGitHub: [@yezhanggg]"
  },
  {
    "objectID": "index.html#about-this-course",
    "href": "index.html#about-this-course",
    "title": "MUSA 5080 Portfolio",
    "section": "",
    "text": "Advanced spatial analysis and data science for urban planning and public policy."
  },
  {
    "objectID": "index.html#portfolio-structure",
    "href": "index.html#portfolio-structure",
    "title": "MUSA 5080 Portfolio",
    "section": "",
    "text": "Weekly Notes: My learning reflections and key concepts\nAssignment: Completed assignments and analyses\nFinal Project: Capstone modeling challenge"
  },
  {
    "objectID": "index.html#about-me",
    "href": "index.html#about-me",
    "title": "MUSA 5080 Portfolio",
    "section": "",
    "text": "My name is Ye and I did my Bachelor in Urban Planning at USC ✌️✌️.\nMy email is yezhang1@upenn.edu\nMy Github user name is yezhanggg\nI think it is a requirement. Also I don’t have any prior experience with R and I think it is powerful tool that would be really helpful for me to know. It has so many potential and implications that I could use in multiple areas and projects."
  },
  {
    "objectID": "index.html#contact",
    "href": "index.html#contact",
    "title": "MUSA 5080 Portfolio",
    "section": "",
    "text": "Email: [yezhang1@design.upenn.edu]\nGitHub: [@yezhanggg]"
  },
  {
    "objectID": "weekly-notes/week-02-notes.html",
    "href": "weekly-notes/week-02-notes.html",
    "title": "Week 2 Notes",
    "section": "",
    "text": "I learned about topics on algorithmic decision making and what is census data.\nWe also went through a scenarios practices where we designed the ethical algorithms.\nThe importance of having algorithmic decision making.\nCensus data is really large but it has a lot of potential to do some great things."
  },
  {
    "objectID": "weekly-notes/week-02-notes.html#key-concepts-learned",
    "href": "weekly-notes/week-02-notes.html#key-concepts-learned",
    "title": "Week 2 Notes",
    "section": "",
    "text": "I learned about topics on algorithmic decision making and what is census data.\nWe also went through a scenarios practices where we designed the ethical algorithms.\nThe importance of having algorithmic decision making.\nCensus data is really large but it has a lot of potential to do some great things."
  },
  {
    "objectID": "weekly-notes/week-02-notes.html#coding-techniques",
    "href": "weekly-notes/week-02-notes.html#coding-techniques",
    "title": "Week 2 Notes",
    "section": "Coding Techniques",
    "text": "Coding Techniques\n\nFunctions that I learned include “str_remove(), str_extract(), str_replace(), case_when(),"
  },
  {
    "objectID": "weekly-notes/week-02-notes.html#questions-challenges",
    "href": "weekly-notes/week-02-notes.html#questions-challenges",
    "title": "Week 2 Notes",
    "section": "Questions & Challenges",
    "text": "Questions & Challenges\n\nI think it will take some time to fully understand how to best use the Census Tract. I think it will take a lot of trials and error. The more pract the better we will get at it."
  },
  {
    "objectID": "weekly-notes/week-02-notes.html#connections-to-policy",
    "href": "weekly-notes/week-02-notes.html#connections-to-policy",
    "title": "Week 2 Notes",
    "section": "Connections to Policy",
    "text": "Connections to Policy\n\nIt is important to understand why we want to do algorthimic decision making in policy.\nData analytics is a subjective process because it involves human decisions. So we need to know to be best clean the data and understand the data."
  },
  {
    "objectID": "weekly-notes/week-02-notes.html#reflection",
    "href": "weekly-notes/week-02-notes.html#reflection",
    "title": "Week 2 Notes",
    "section": "Reflection",
    "text": "Reflection\n\nLooking forward to explore the census data more and to see what insightful result we could get. Also really looking forward to the data update in the end of this year. To see how status have changed for people."
  },
  {
    "objectID": "weekly-notes/week-04-notes.html",
    "href": "weekly-notes/week-04-notes.html",
    "title": "Week 4 Notes",
    "section": "",
    "text": "We learned about spatial data in R. We talked about vector data model and different type of spatial data to use in R. We also talked about some spatial data operation of how to filter and select the data that we need. We also mentioned some corrdinate reference system and how each is created."
  },
  {
    "objectID": "weekly-notes/week-04-notes.html#key-concepts-learned",
    "href": "weekly-notes/week-04-notes.html#key-concepts-learned",
    "title": "Week 4 Notes",
    "section": "",
    "text": "We learned about spatial data in R. We talked about vector data model and different type of spatial data to use in R. We also talked about some spatial data operation of how to filter and select the data that we need. We also mentioned some corrdinate reference system and how each is created."
  },
  {
    "objectID": "weekly-notes/week-04-notes.html#coding-techniques",
    "href": "weekly-notes/week-04-notes.html#coding-techniques",
    "title": "Week 4 Notes",
    "section": "Coding Techniques",
    "text": "Coding Techniques\n\nBelow are some of the core techniques that we covered in class and used in class. | st_filter() | Select features by spatial relationship | Find neighboring counties | | st_buffer() | Create zones around features | Hospital service areas | | st_intersects() | Test spatial overlap | Check access to services | | st_disjoint() | Test spatial separation | Find rural areas | | st_join() | Join by location | Add county info to tracts | | st_union() | Combine geometries | Merge overlapping buffers | | st_intersection() | Clip geometries | Calculate overlap areas | | st_transform() | Change CRS | Accurate distance/area calculations | | st_area() | Calculate areas | County sizes, coverage | | st_distance() | Calculate distances | Distance to facilities |"
  },
  {
    "objectID": "weekly-notes/week-04-notes.html#questions-challenges",
    "href": "weekly-notes/week-04-notes.html#questions-challenges",
    "title": "Week 4 Notes",
    "section": "Questions & Challenges",
    "text": "Questions & Challenges\n\nI think it is very important to understand what kind of spatial relationship you want to explore. That determines what types of function you need to explore relationships. ‘st_filter()’ and ‘st_intersection()’ might seem confusing at first but they are serving differe kinds of operation."
  },
  {
    "objectID": "weekly-notes/week-04-notes.html#connections-to-policy",
    "href": "weekly-notes/week-04-notes.html#connections-to-policy",
    "title": "Week 4 Notes",
    "section": "Connections to Policy",
    "text": "Connections to Policy\n\nThese operations are heavily related to Policy. Policy decision need spatial analysis to fully understand the root issues."
  },
  {
    "objectID": "weekly-notes/week-04-notes.html#reflection",
    "href": "weekly-notes/week-04-notes.html#reflection",
    "title": "Week 4 Notes",
    "section": "Reflection",
    "text": "Reflection\n\nBeing able to master the spatial analysis and GIS in R will unlock great potential in coming up with policy decision and more in-depth analysis for urban issues."
  }
]