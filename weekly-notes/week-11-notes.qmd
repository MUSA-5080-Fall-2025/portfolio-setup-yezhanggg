---
title: "Week 11 Notes"
date: "2025-11-17"
---

## Key Concepts Learned

- Panel data = same units (bike stations) tracked over time, so each row is a station × hour combo instead of just one snapshot like our housing price data from earlier weeks
- Temporal lags are basically the time version of Week 6's spatial features - instead of "crimes within 500ft," we're using "demand 1 hour ago" or "demand yesterday same time"
- Big difference from Week 7's spatial lag model: we use PAST outcomes not NEIGHBOR outcomes, so we can actually forecast forward without the circular dependency problem

## Coding Techniques

- `floor_date(ymd_hms(start_time), unit = "hour")` to bin messy timestamps into clean hourly intervals
- `expand.grid()` is key - creates every possible station-hour combo so we have a complete panel, then join actual trips and fill NAs with 0 (lag calculations break if rows are missing)
- Lag creation: `arrange(from_station_id, interval60) %>% group_by(from_station_id) %>% mutate(lag1Hour = lag(Trip_Count, 1))` - the grouping matters so lags stay within each station
- Station fixed effects with `as.factor(from_station_id)` in the regression to control for some stations just being busier

## Questions & Challenges

- Temporal validation tripped me up at first - you HAVE to train on earlier weeks and test on later weeks, not the other way around (can't use future to predict past, obviously)
- Model building is incremental: start with time + weather baseline, then add lags, demographics, fixed effects, holiday dummies - lags give the biggest boost
- Using MAE instead of RMSE here because it's more interpretable ("off by ~5 trips" makes more sense operationally)

## Connections to Policy

- The actual use case: predict which stations will be empty by 8 AM rush hour so rebalancing trucks can move bikes overnight
- Equity issue comes up again - if the model predicts worse in low-income neighborhoods, we're basically giving them worse bike service
- Same feedback loop problem as Week 10 predictive policing: bad predictions → no bikes → people stop trying → less data → even worse predictions

## Reflection

- Weeks 6-7-11 all follow the same logic: use nearby info as features (space or time), validate on held-out data (spatial CV or time split) - it's clicking now
- The real question isn't just "is MAE good enough" but "who's getting screwed by our errors" - if mistakes cluster in certain neighborhoods that's a problem even if overall accuracy looks fine